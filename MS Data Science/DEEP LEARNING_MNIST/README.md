# ğŸ§  Foundations of Deep Learning: MNIST Digit Recognition  
# AUTHOR
Swetha Yanamandhalla

Date:Dec 13,2024


 ## Enhanced neural network architecture achieving 85.3% accuracy on MNIST! 

---

## Project Overview  
This repository contains **two Jupyter notebooks** designed to implement, analyze, and compare different deep learning architectures for digit classification on the **MNIST dataset**. The goal is to evaluate improvements in performance when extending a baseline neural network.  

## Notebooks Included:  
## extended_network.ipynb â€“ An optimized architecture with additional layers and modifications.  
## original_network.ipynb â€“ A benchmark implementation of the original network.  

---

## Notebook Descriptions  

### extended_network.ipynb  
ğŸ”¸ Implements an **extended version** of the original neural network.  
ğŸ”¸ **12 code cells** covering architecture design, training, and evaluation.  
ğŸ”¸ Introduces enhancements to improve accuracy and model generalization.  

### ğŸ”¹ `original_network.ipynb`  
ğŸ”¸ Implements the **baseline neural network** for comparison.  
ğŸ”¸ **12 code cells** focused on defining, training, and evaluating the network.  
ğŸ”¸ Serves as a reference model to measure improvements made in the extended version.  

---

## How to Use 

1ï¸âƒ£ Ensure **Python 3.8+** is installed on your system.  
2ï¸âƒ£ Install the necessary dependencies:  
   ```bash
   pip install tensorflow torch numpy matplotlib jupyter
   ```  
3ï¸âƒ£ Open Jupyter Notebook:  
   ```bash
   jupyter notebook
   ```  
4ï¸âƒ£ Run the notebooks in order to **train and evaluate** the models.  

---

## Project Structure  

 ## extended_network.ipynb â€“ Advanced neural network with improved architecture.  
 ## original_network.ipynb â€“ Standard baseline model for comparison.  

---

## Purpose  
The aim of this project is to **analyze the impact of architectural changes** in neural networks by comparing the **extended model against the original version**. By running the notebooks, users can:  
âœ”ï¸ Observe improvements in model accuracy.  
âœ”ï¸ Understand the role of additional layers and optimizations.  
âœ”ï¸ Evaluate trade-offs in computation and performance.  

---

## Results  
ğŸ”¹ The **extended network achieved 85.3% accuracy**, demonstrating significant improvement over the original architecture.  
ğŸ”¹ Detailed **performance metrics** and visualizations are available in the output sections of each notebook.  

---

## License  
This project is **open-source** under the **MIT License** â€“ feel free to use, modify, and build upon it!  

---
## Contact
For any inquiries or suggestions, feel free to reach out:
- **Name**: Swetha
- **Email**: swethachowdhary33@gmail.com
- **GitHub**: [SWETHAY9](https://github.com/swethay9)


